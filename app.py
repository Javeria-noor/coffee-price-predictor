# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MnOJQrgTSYZHxwCr7re0Vw7G9CBe-r9Y
"""



import pandas as pd

# Load the CSV file
df = pd.read_csv("index_1.csv")

# Show first 5 rows
df.head()

# Check for missing values
missing = df.isnull().sum()
print("Missing values in each column:")
print(missing)



# Data types of each column
print("Data Types:")
print(df.dtypes)

# Unique values in each column
print("\nUnique Values Per Column:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

# Summary statistics for numeric columns
print("Summary Statistics (Mean, Std, Min, Max, etc.):")
print(df.describe())

# Median for numeric columns
print("\nMedian:")
print(df.median(numeric_only=True))

# Mode for all columns
print("\nMode:")
print(df.mode().iloc[0])

import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set(style="whitegrid")

# Histogram of money column
plt.figure(figsize=(8, 5))
sns.histplot(df['money'], bins=20, kde=True)
plt.title('Distribution of Money (Coffee Prices)')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 4))
sns.boxplot(x=df['money'])
plt.title('Box Plot of Money (Price)')
plt.xlabel('Money')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Scatter plot: datetime vs. money
plt.figure(figsize=(10,5))
plt.scatter(df['datetime'], df['money'], alpha=0.5)
plt.title('Money Spent Over Time')
plt.xlabel('Datetime')
plt.ylabel('Money')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

# Correlation matrix
correlation = df.corr(numeric_only=True)
print(correlation)

# Check for missing values
missing = df.isnull().sum()
print("Missing values in each column:")
print(missing)

import pandas as pd

# Load your CSV file (you've already done this)
df = pd.read_csv("index_1.csv")

# Fill missing card numbers with 'Unknown'
df['card'] = df['card'].fillna("Unknown")

#  Check again to confirm no missing values
print(df.isnull().sum())

# Check data types of each column
print("Data Types:")
print(df.dtypes)

print("\nUnique value counts in each column:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

import seaborn as sns
import matplotlib.pyplot as plt

# Select only numeric columns
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Correlation matrix
correlation = numeric_df.corr()

# Plot heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(correlation, annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Count plot for 'cash_type'
sns.countplot(data=df, x='cash_type')
plt.title("Distribution of Cash Type")
plt.show()

# Count plot for 'coffee_name' (top 10 only for better visibility)
top_coffee = df['coffee_name'].value_counts().nlargest(10)
top_coffee.plot(kind='bar')
plt.title("Top 10 Coffee Types")
plt.xlabel("Coffee Name")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()

# Value counts for 'card' (showing top 5 for brevity)
print("Top 5 Card Numbers:")
print(df['card'].value_counts().head())

# Check data types of each column
print("Data Types of Each Column:")
print(df.dtypes)

# Count unique values in each column
print("\nUnique Value Counts in Each Column:")
for column in df.columns:
    unique_count = df[column].nunique()
    print(f"{column}: {unique_count} unique values")

# Make sure 'date' is in datetime format
df['date'] = pd.to_datetime(df['date'])

# Optional: If 'datetime' column needs conversion too
df['datetime'] = pd.to_datetime(df['datetime'])

import matplotlib.pyplot as plt

# Group by date and sum the money
daily_sales = df.groupby('date')['money'].sum()

# Plot the daily sales trend
plt.figure(figsize=(12, 6))
daily_sales.plot()
plt.title("Daily Coffee Sales Trend")
plt.xlabel("Date")
plt.ylabel("Total Money Earned")
plt.grid(True)
plt.show()

# Extract hour from datetime
df['hour'] = df['datetime'].dt.hour

# Group by hour
hourly_sales = df.groupby('hour')['money'].sum()

# Plot
plt.figure(figsize=(10, 5))
hourly_sales.plot(kind='bar', color='skyblue')
plt.title("Hourly Coffee Sales Trend")
plt.xlabel("Hour of Day")
plt.ylabel("Total Money Earned")
plt.grid(axis='y')
plt.show()

grouped_coffee = df.groupby('coffee_name')['money'].sum().sort_values(ascending=False)
print(grouped_coffee)

# Optional: Plot it
grouped_coffee.plot(kind='bar', figsize=(12, 5), title='Total Sales by Coffee Type')

avg_cash_type = df.groupby('cash_type')['money'].mean()
print(avg_cash_type)

# Optional plot
avg_cash_type.plot(kind='bar', title='Average Money by Payment Type', color='orange')

daily_sales = df.groupby('date')['money'].sum()
daily_sales.plot(figsize=(12, 5), title='Total Sales per Day')



import seaborn as sns
import matplotlib.pyplot as plt

# Select only numerical columns for pairplot
numerical_cols = ['money']  # Currently you only have 'money' as numeric
sns.pairplot(df[numerical_cols])
plt.show()

grouped_coffee = df.groupby('coffee_name')['money'].mean().sort_values(ascending=False)
print(grouped_coffee)

grouped_cash = df.groupby('cash_type')['money'].sum()
print(grouped_cash)

grouped_coffee.plot(kind='bar', figsize=(10,5), title="Avg Money per Coffee Type")
plt.ylabel("Average Money")
plt.show()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

# Encode 'cash_type'
df['cash_type_encoded'] = le.fit_transform(df['cash_type'])

# Encode 'coffee_name'
df['coffee_name_encoded'] = le.fit_transform(df['coffee_name'])

df.head()

from sklearn.preprocessing import MinMaxScaler

# Create scaler object
scaler = MinMaxScaler()

# Scale 'money' column
df['money_scaled'] = scaler.fit_transform(df[['money']])

# Check updated DataFrame
df[['money', 'money_scaled']].head()

from sklearn.model_selection import train_test_split

# Select features and target
X = df[['cash_type_encoded', 'coffee_name_encoded', 'money_scaled']]
y = df['cash_type_encoded']  # You can change target later depending on your model's goal

# Split into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Show the shape of datasets
print("Training Features Shape:", X_train.shape)
print("Testing Features Shape:", X_test.shape)

# Drop columns that won't be used in model
df = df.drop(columns=['card', 'datetime', 'date'])

# (Optional) Confirm final data structure
print(df.head())

from sklearn.preprocessing import LabelEncoder

# Re-initialize your data if you reloaded
df = pd.read_csv("index_1.csv")

# Fill missing cards again if needed
df['card'] = df['card'].fillna("Unknown")

# Encode categorical variables
le = LabelEncoder()
df['cash_type_encoded'] = le.fit_transform(df['cash_type'])
df['coffee_name_encoded'] = le.fit_transform(df['coffee_name'])

X = df[['cash_type_encoded', 'coffee_name_encoded']]
y = df['money']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)

# Print evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("✅ Mean Squared Error (MSE):", mse)
print("✅ R-squared Score (R2):", r2)

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Predict using the trained model
y_pred = model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder

# Title
st.title("Coffee Sales Analysis and Price Prediction")

# Load Data
st.header("1. Load Dataset")
df = pd.read_csv("index_1.csv")
df['card'].fillna("Unknown", inplace=True)
st.write(df.head())


# Introduction
st.header("2. Introduction")
st.write("""
This dataset contains sales data of coffee including information like:
- Date and time
- Cash type (cash/card)
- Card number (if any)
- Coffee name
- Price (money)

**Goal**: Predict coffee price and understand trends.
""")

# EDA Section
st.header("3. Exploratory Data Analysis (EDA)")

st.subheader("Summary Statistics")
st.write(df['money'].describe())

st.subheader("Histogram")
fig, ax = plt.subplots()
df['money'].hist(bins=20, ax=ax)
st.pyplot(fig)

st.subheader("Box Plot")
fig2, ax2 = plt.subplots()
sns.boxplot(y=df['money'], ax=ax2)
st.pyplot(fig2)

st.subheader("Correlation Heatmap")
le = LabelEncoder()
df['cash_type_encoded'] = le.fit_transform(df['cash_type'])
df['coffee_name_encoded'] = le.fit_transform(df['coffee_name'])

fig3, ax3 = plt.subplots()
sns.heatmap(df[['money', 'cash_type_encoded', 'coffee_name_encoded']].corr(), annot=True, ax=ax3)
st.pyplot(fig3)

# Model Section
st.header("4. Model and Predictions")

# Features and Target
X = df[['cash_type_encoded', 'coffee_name_encoded']]
y = df['money']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Training
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

st.subheader("Model Performance")
st.write(f"Root Mean Squared Error (RMSE): {rmse:.2f}")

# Runtime Prediction
st.subheader("Predict Coffee Price")

cash_type_input = st.selectbox("Select Payment Type", df['cash_type'].unique())
coffee_name_input = st.selectbox("Select Coffee Name", df['coffee_name'].unique())

cash_type_encoded = le.fit(df['cash_type']).transform([cash_type_input])[0]
coffee_encoded = le.fit(df['coffee_name']).transform([coffee_name_input])[0]

input_features = np.array([[cash_type_encoded, coffee_encoded]])
predicted_price = model.predict(input_features)

st.write(f"### Predicted Price: Rs. {predicted_price[0]:.2f}")

# Conclusion
st.header("5. Conclusion")
st.write("""
- Most coffee prices fall between Rs. 28 and Rs. 36
- Coffee type has a greater influence on price than payment type
- Our model helps predict price using coffee and payment info in real-time
""")